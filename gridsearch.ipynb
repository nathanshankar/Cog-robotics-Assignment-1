{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling2D\n",
    ")\n",
    "from tensorflow.keras import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_text, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=hp.Choice(\n",
    "                    'num_filters',\n",
    "                    values=[32, 64],\n",
    "                    default=64,\n",
    "                ),\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_2',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "NUM_CLASSES = 10  # cifar10 number of classes\n",
    "INPUT_SHAPE = (32, 32, 3)  # cifar10 images input shape\n",
    "\n",
    "HYPERBAND_MAX_EPOCHS = 40\n",
    "MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    seed=42,\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='random_search',\n",
    "    project_name='cifar10'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 11m 51s]\n",
      "val_accuracy: 0.6707500219345093\n",
      "\n",
      "Best val_accuracy So Far: 0.6886500120162964\n",
      "Total elapsed time: 01h 25m 36s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0                 |0                 |dropout_1\n",
      "32                |32                |num_filters\n",
      "0.45              |0.1               |dropout_2\n",
      "288               |512               |units\n",
      "sigmoid           |tanh              |dense_activation\n",
      "0.15              |0.45              |dropout_3\n",
      "0.00024495        |0.00015159        |learning_rate\n",
      "\n",
      "Epoch 1/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.2288 - loss: 2.1106 - val_accuracy: 0.4415 - val_loss: 1.5068\n",
      "Epoch 2/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.4403 - loss: 1.5182 - val_accuracy: 0.5391 - val_loss: 1.2857\n",
      "Epoch 3/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5089 - loss: 1.3522 - val_accuracy: 0.5662 - val_loss: 1.2136\n",
      "Epoch 4/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5456 - loss: 1.2549 - val_accuracy: 0.5992 - val_loss: 1.1245\n",
      "Epoch 5/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5733 - loss: 1.1960 - val_accuracy: 0.6102 - val_loss: 1.0940\n",
      "Epoch 6/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5966 - loss: 1.1389 - val_accuracy: 0.6322 - val_loss: 1.0418\n",
      "Epoch 7/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 1.0915 - val_accuracy: 0.6257 - val_loss: 1.0363\n",
      "Epoch 8/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6213 - loss: 1.0553 - val_accuracy: 0.6526 - val_loss: 0.9728\n",
      "Epoch 9/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6367 - loss: 1.0162 - val_accuracy: 0.6658 - val_loss: 0.9336\n",
      "Epoch 10/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6490 - loss: 0.9863 - val_accuracy: 0.6702 - val_loss: 0.9262\n",
      "Epoch 11/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6681 - loss: 0.9394 - val_accuracy: 0.6631 - val_loss: 0.9328\n",
      "Epoch 12/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6724 - loss: 0.9266 - val_accuracy: 0.6880 - val_loss: 0.8870\n",
      "Epoch 13/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6804 - loss: 0.9107 - val_accuracy: 0.6935 - val_loss: 0.8707\n",
      "Epoch 14/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6874 - loss: 0.8789 - val_accuracy: 0.7043 - val_loss: 0.8442\n",
      "Epoch 15/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6945 - loss: 0.8596 - val_accuracy: 0.6967 - val_loss: 0.8472\n",
      "Epoch 16/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6980 - loss: 0.8546 - val_accuracy: 0.7049 - val_loss: 0.8315\n",
      "Epoch 17/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7071 - loss: 0.8293 - val_accuracy: 0.7090 - val_loss: 0.8147\n",
      "Epoch 18/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7061 - loss: 0.8280 - val_accuracy: 0.7029 - val_loss: 0.8333\n",
      "Epoch 19/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7115 - loss: 0.8108 - val_accuracy: 0.7124 - val_loss: 0.8099\n",
      "Epoch 20/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7208 - loss: 0.7958 - val_accuracy: 0.7170 - val_loss: 0.8059\n",
      "Epoch 21/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7229 - loss: 0.7827 - val_accuracy: 0.7109 - val_loss: 0.8084\n",
      "Epoch 22/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7249 - loss: 0.7717 - val_accuracy: 0.7132 - val_loss: 0.8035\n",
      "Epoch 23/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 0.7602 - val_accuracy: 0.7220 - val_loss: 0.7921\n",
      "Epoch 24/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.7462 - val_accuracy: 0.7281 - val_loss: 0.7829\n",
      "Epoch 25/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7308 - loss: 0.7489 - val_accuracy: 0.7245 - val_loss: 0.7806\n",
      "Epoch 26/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 0.7308 - val_accuracy: 0.7304 - val_loss: 0.7624\n",
      "Epoch 27/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.7222 - val_accuracy: 0.7279 - val_loss: 0.7678\n",
      "Epoch 28/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.7159 - val_accuracy: 0.7251 - val_loss: 0.7735\n",
      "Epoch 29/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.7050 - val_accuracy: 0.7307 - val_loss: 0.7676\n",
      "Epoch 30/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7474 - loss: 0.7057 - val_accuracy: 0.7254 - val_loss: 0.7804\n",
      "Epoch 31/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7537 - loss: 0.6979 - val_accuracy: 0.7338 - val_loss: 0.7615\n",
      "Epoch 32/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7589 - loss: 0.6812 - val_accuracy: 0.7296 - val_loss: 0.7725\n",
      "Epoch 33/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.6778 - val_accuracy: 0.7353 - val_loss: 0.7555\n",
      "Epoch 34/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7539 - loss: 0.6920 - val_accuracy: 0.7400 - val_loss: 0.7426\n",
      "Epoch 35/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7621 - loss: 0.6649 - val_accuracy: 0.7404 - val_loss: 0.7435\n",
      "Epoch 36/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.6612 - val_accuracy: 0.7336 - val_loss: 0.7600\n",
      "Epoch 37/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7661 - loss: 0.6551 - val_accuracy: 0.7470 - val_loss: 0.7274\n",
      "Epoch 38/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 0.6513 - val_accuracy: 0.7401 - val_loss: 0.7389\n",
      "Epoch 39/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7703 - loss: 0.6528 - val_accuracy: 0.7433 - val_loss: 0.7342\n",
      "Epoch 40/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7723 - loss: 0.6483 - val_accuracy: 0.7405 - val_loss: 0.7603\n",
      "Epoch 1/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.2451 - loss: 2.0591 - val_accuracy: 0.4710 - val_loss: 1.4552\n",
      "Epoch 2/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.4516 - loss: 1.5040 - val_accuracy: 0.5273 - val_loss: 1.3174\n",
      "Epoch 3/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5081 - loss: 1.3536 - val_accuracy: 0.5684 - val_loss: 1.2039\n",
      "Epoch 4/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5472 - loss: 1.2522 - val_accuracy: 0.5752 - val_loss: 1.1730\n",
      "Epoch 5/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5724 - loss: 1.1978 - val_accuracy: 0.6046 - val_loss: 1.1069\n",
      "Epoch 6/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 1.1369 - val_accuracy: 0.6232 - val_loss: 1.0526\n",
      "Epoch 7/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 1.0749 - val_accuracy: 0.6411 - val_loss: 0.9999\n",
      "Epoch 8/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6263 - loss: 1.0443 - val_accuracy: 0.6536 - val_loss: 0.9725\n",
      "Epoch 9/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6431 - loss: 1.0000 - val_accuracy: 0.6528 - val_loss: 0.9695\n",
      "Epoch 10/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6509 - loss: 0.9803 - val_accuracy: 0.6635 - val_loss: 0.9518\n",
      "Epoch 11/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6585 - loss: 0.9519 - val_accuracy: 0.6828 - val_loss: 0.8966\n",
      "Epoch 12/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6739 - loss: 0.9205 - val_accuracy: 0.6887 - val_loss: 0.8945\n",
      "Epoch 13/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6735 - loss: 0.9208 - val_accuracy: 0.6700 - val_loss: 0.9335\n",
      "Epoch 14/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.6922 - loss: 0.8768 - val_accuracy: 0.6859 - val_loss: 0.8913\n",
      "Epoch 15/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.6894 - loss: 0.8810 - val_accuracy: 0.6954 - val_loss: 0.8695\n",
      "Epoch 16/40\n",
      "\u001b[1m1069/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6944 - loss: 0.8604"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\natha.NSLEGION\\Desktop\\Cog robotics Assignment 1\\gridsearch.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natha.NSLEGION/Desktop/Cog%20robotics%20Assignment%201/gridsearch.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m N_EPOCH_SEARCH \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/natha.NSLEGION/Desktop/Cog%20robotics%20Assignment%201/gridsearch.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x_train, y_train, epochs\u001b[39m=\u001b[39;49mN_EPOCH_SEARCH, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[39m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\natha.NSLEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCH_SEARCH = 40\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=N_EPOCH_SEARCH, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
